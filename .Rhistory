install.packages("ggraph")
install.packages("ggforce")
install.packages("igraph")
install.packages("tidytext")
library(ggraph)
library(ggforce)
library(igraph)
library(tidytext)
df <- read.csv('data_scrape/reddit_posts_all.csv', sep="\t")
install.packages("pattern.nlp")
devtools::install_github("bnosac/pattern.nlp", INSTALL_opts = "--no-multiarch")
## Natural Language Processing: POS tagging
library(pattern.nlp)
install.packages("quanteda")
library(quanteda)
tweet_dfm <- dfm(df$body, remove_punct = TRUE)
df_dfm <- as.dfm(df$body)
df_dfm <- as.dfm(df)
tweet_dfm <- dfm(df_dfm$body, remove_punct = TRUE)
tweet_dfm <- dfm(df_dfm, remove_punct = TRUE)
head(tweet_dfm)
df_body <- df$body
df_dfm <- as.dfm(df_body)
df_body <- as.data.frame(df$body)
df_dfm <- as.dfm(df_body)
tweet_dfm <- dfm(df_dfm, remove_punct = TRUE)
head(tweet_dfm)
View(df)
df <- read.csv('data_scrape/reddit_posts_all.csv', sep="\t",fileEncoding = "UTF-8")
View(df)
df_body <- as.data.frame(df$body)
df_dfm <- as.dfm(df_body)
tweet_dfm <- dfm(df_dfm, remove_punct = TRUE)
head(tweet_dfm)
df_body <- data.frame(df$body)
View(df_body)
df_dfm <- as.dfm(df_body)
View(df_dfm)
View(df_body)
library(tm)
myCorpus <- Corpus(VectorSource(df$body))
tdm <- TermDocumentMatrix(myCorpus)
View(tdm)
df_dfm <- as.dfm(tdm)
tweet_dfm <- dfm(df_dfm, remove_punct = TRUE)
head(tweet_dfm)
tag_dfm <- dfm_select(tweet_dfm, pattern = ("#*"))
toptag <- names(topfeatures(tag_dfm, 50))
head(toptag)
toks <- corpus_subset(df$body) %>%
tokens(remove_punct = TRUE) %>%
tokens_tolower() %>%
tokens_remove(pattern = stopwords("english"), padding = FALSE)
fcmat <- fcm(toks, context = "window", tri = FALSE)
feat <- names(topfeatures(fcmat, 30))
fcm_select(fcmat, pattern = feat) %>%
textplot_network(min_freq = 0.5)
toks <- corpus_subset(myCorpus) %>%
tokens(remove_punct = TRUE) %>%
tokens_tolower() %>%
tokens_remove(pattern = stopwords("english"), padding = FALSE)
fcmat <- fcm(toks, context = "window", tri = FALSE)
feat <- names(topfeatures(fcmat, 30))
fcm_select(fcmat, pattern = feat) %>%
textplot_network(min_freq = 0.5)
toks <- corpus_subset(myCorpus) %>%
tokens(remove_punct = TRUE) %>%
tokens_tolower() %>%
tokens_remove(pattern = stopwords("english"), padding = FALSE)
toks <- corpus_subset(tdm) %>%
tokens(remove_punct = TRUE) %>%
tokens_tolower() %>%
tokens_remove(pattern = stopwords("english"), padding = FALSE)
textplot_network(df_dfm)
textplot_network(df_dfm, min_freq = 0.5)
textplot_network(df_dfm, min_freq = 0.8)
textplot_network(df_dfm, min_freq = 0.99)
textplot_network(df_dfm, min_freq = 0.999)
feat <- names(topfeatures(df_dfm, 30))
textplot_network(feat)
feat <- names(topfeatures(df_dfm, 30))
textplot_network(feat)
require(quanteda)
mt <- dfm(tdm, remove_punct = TRUE, remove = stopwords())
mt <- dfm(myCorpus, remove_punct = TRUE, remove = stopwords())
mt <- dfm(df_dfm, remove_punct = TRUE, remove = stopwords())
mt <- dfm_trim(mt, min_termfreq = 100)
sim <- textstat_proxy(mt, margin = "features")
textplot_network(quanteda:::as.fcm(as(sim, "dgTMatrix")), min_freq = 0.95)
library(devtools)
install_github("cbail/textnets")
library(textnets)
library(dplyr)
library(Matrix)
library(tidytext)
library(stringr)
library(SnowballC)
library(reshape2)
library(phrasemachine)
library(igraph)
library(ggraph)
library(networkD3)
install_github("cbail/textnets")
library(textnets)
install.packages("textnets")
library(igraph)
tdm)
termDocMatrix <- as.matrix(tdm)
termDocMatrix[termDocMatrix>=1] <- 1
termMatrix <- termDocMatrix %*% t(termDocMatrix)
termMatrix[5:10,5:10]
library(igraph)
g <- graph.adjacency(termMatrix, weighted=T, mode = "undirected")
g <- simplify(g)
V(g)$label <- V(g)$name
V(g)$degree <- degree(g)
set.seed(3952)
layout1 <- layout.fruchterman.reingold(g)
plot(g, layout=layout1)
plot(g, layout=layout1)
termMatrix <- termMatrix[5:10,5:10]
g <- graph.adjacency(termMatrix, weighted=T, mode = "undirected")
g <- simplify(g)
V(g)$label <- V(g)$name
V(g)$degree <- degree(g)
set.seed(3952)
layout1 <- layout.fruchterman.reingold(g)
plot(g, layout=layout1)
termMatrix <- termMatrix[5:50,5:50]
termDocMatrix <- as.matrix(tdm)
termDocMatrix[termDocMatrix>=1] <- 1
termMatrix <- termDocMatrix %*% t(termDocMatrix)
termMatrix <- termMatrix[5:50,5:50]
g <- graph.adjacency(termMatrix, weighted=T, mode = "undirected")
g <- simplify(g)
V(g)$label <- V(g)$name
V(g)$degree <- degree(g)
set.seed(3952)
layout1 <- layout.fruchterman.reingold(g)
plot(g, layout=layout1)
V(g)$label.cex <- 2.2 * V(g)$degree / max(V(g)$degree)+ .2
V(g)$label.color <- rgb(0, 0, .2, .8)
V(g)$frame.color <- NA
egam <- (log(E(g)$weight)+.4) / max(log(E(g)$weight)+.4)
E(g)$color <- rgb(.5, .5, 0, egam)
E(g)$width <- egam
plot(g, layout=layout1)
plot(g)
plot(g)
plot(g)
plot(g)
plot(g, layout=layout.kamada.kawai)
plot(g, layout=layout.kamada.kawai)
plot(g, layout=layout.kamada.kawai)
plot(g)
tkplot(g, layout=layout.kamada.kawai)
tkplot(g, layout=layout.kamada.kawai)
install.packages("sentimentr")
library(sentimentr)
df <- read.csv('data_scrape/reddit_posts_all.csv', sep="\t",fileEncoding = "UTF-8")
View(df)
df <- read.csv('data_scrape/reddit_posts_all.csv', sep="\t")
View(df)
df <- read.csv('data_scrape/reddit_posts_all.csv',
sep="\t",
fileEncoding = "UTF-8")
df <- read.csv('data_scrape/reddit_posts_all.csv', sep="\t",fileEncoding = "UTF-8")
df <- read.csv('data_scrape/reddit_posts_all.csv',
sep="\t"
, encoding="UTF-8", stringsAsFactors=FALSE)
View(df)
sentiment=sentiment_by(df$body)
View(sentiment)
(sentiment$ave_sentiment)
summary(sentiment$ave_sentiment)
library(ggplot2)
qplot(sentiment$ave_sentiment,   geom="histogram",binwidth=0.1,main="Review Sentiment Histogram")
df$ave_sentiment=sentiment$ave_sentiment
View(df)
plot(df$timestamp, df$ave_sentiment)
View(df)
ggplot(df$ave_sentiments, aes(df$timestamp, df$ave_sentiment)) + geom_line() +
scale_x_date(format = "%b-%Y") + xlab("") + ylab("Daily Views")
ggplot(df$ave_sentiments, aes(df$timestamp, df$ave_sentiment)) +
geom_line() +
# scale_x_date(format = "%b-%Y") +
xlab("") +
ylab("Daily Views")
ggplot(df$ave_sentiments, aes(df$timestamp, df$ave_sentiment)) +
geom_line() +
# scale_x_date(format = "%b-%Y") +
xlab("") +
ylab("Average Sentiment")
View(df)
ggplot(df, aes(df$timestamp, df$ave_sentiment)) +
geom_line() +
# scale_x_date(format = "%b-%Y") +
xlab("") +
ylab("Average Sentiment")
df$date <- df$timestamp %>% date()
df$date <- df$timestamp %>% date(.)
df$date <- (df$timestamp %>% date(.))
df$date <- as.Date(df$timestamp, "%m/%d/%Y")
View(df)
df$date <- as.Date(as.timestamp(df$timestamp), "%m/%d/%Y")
df$date <- substr(df$timestamp, 1, 10)
View(df)
df_sentiment_by_day <- aggregate(ave_sentiment ~ date, df, avg)
df_sentiment_by_day <- aggregate(ave_sentiment ~ date, df, mean)
View(df)
df$sentiment_by_day <- aggregate(ave_sentiment ~ date, df, mean)
df_sentiment_by_day
ggplot(df_sentiment_by_day, aes(df_sentiment_by_day$date, df_sentiment_by_day$ave_sentiment)) +
geom_line() +
# scale_x_date(format = "%b-%Y") +
xlab("") +
ylab("Average Sentiment")
plot(df_sentiment_by_day)
ggplot(df_sentiment_by_day)
ggplot(df_sentiment_by_day, aes(x=date, y=ave_sentiment))
ggplot(df_sentiment_by_day, aes(x=date, y=ave_sentiment)) + geom_point()
ggplot(df_sentiment_by_day, aes(x=date, y=ave_sentiment)) +
geom_point()+
scale_x_date(format = "%b-%Y") +
xlab("") +
ylab("Average Sentiment")
ggplot(df_sentiment_by_day, aes(x=date, y=ave_sentiment)) +
geom_point()+
xlab("") +
ylab("Average Sentiment")
ggplot(df_sentiment_by_day, aes(x=date, y=ave_sentiment)) +
geom_line()+
xlab("") +
ylab("Average Sentiment")
ggplot(df_sentiment_by_day, aes(x=date, y=ave_sentiment)) +
geom_point()+
geom_line()
ggplot(df_sentiment_by_day, aes(x=date, y=ave_sentiment)) +
geom_point()+
geom_line() +
xlab("") +
ylab("Average Sentiment")
ggplot(df_sentiment_by_day, aes(x=date, y=ave_sentiment,group=1)) +
geom_point()+
geom_line() +
xlab("") +
ylab("Average Sentiment")
write.csv(df,
"df_with_sentiment.csv",
row.names = TRUE)
write.csv(df,
"daily_avg_sentiment.csv",
row.names = TRUE)
ggplot(df_sentiment_by_day, aes(x=date, y=ave_sentiment,group=1)) +
geom_point()+
geom_line() +
scale_x_date() +
xlab("") +
ylab("Average Sentiment")
View(df_sentiment_by_day)
df_sentiment_by_day$date <- as.Date(df_sentiment_by_day$date)
ggplot(df_sentiment_by_day, aes(x=date, y=ave_sentiment,group=1)) +
geom_point()+
geom_line() +
scale_x_date() +
xlab("") +
ylab("Average Sentiment")
